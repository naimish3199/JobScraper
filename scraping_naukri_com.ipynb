{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from math import ceil\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/bank-jobs?xt=catsrch&qf[]=6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = webdriver.ChromeOptions()\n",
    "# option.add_argument('--headless')\n",
    "option.add_argument(\"--disable-web-security\")\n",
    "option.add_argument(\"--disable-site-isolation-trials\")\n",
    "option.add_argument(\"--disable-features=SameSiteByDefaultCookies\")\n",
    "option.add_argument('--disable-gpu')\n",
    "option.add_argument('--disable-extensions')\n",
    "option.add_argument('--no-sandbox')\n",
    "\n",
    "browser = webdriver.Chrome(options = option)\n",
    "browser.get(url)\n",
    "browser.maximize_window()\n",
    "sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(browser):\n",
    "    \n",
    "    job_list = []\n",
    "    \n",
    "    job_elements = browser.find_elements(By.CLASS_NAME, \"srp-jobtuple-wrapper\")\n",
    "    if len(job_elements) == 0:\n",
    "        print(\"Elements not found\")\n",
    "        \n",
    "    # Loop through each job element and extract the required information\n",
    "    for job in job_elements:\n",
    "        \n",
    "        # Create a dictionary to store the current job's information\n",
    "        job_info = {}\n",
    "\n",
    "        # Extract job title\n",
    "        job_info['Job Title'] = job.find_element(By.CLASS_NAME, \"title\").text\n",
    "\n",
    "        # Extract company name\n",
    "        job_info['Company Name'] = job.find_element(By.CLASS_NAME, \"comp-name\").text\n",
    "\n",
    "        try:\n",
    "            experience_walk_in_date_element = job.find_element(\"css selector\", \"span.ni-job-tuple-icon.ni-job-tuple-icon-srp-experience.exp\")\n",
    "            experience = experience_walk_in_date_element.text\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            experience = \"\"\n",
    "            \n",
    "        try:\n",
    "            experience_walk_in_date_element = job.find_element(\"css selector\", \"span.ni-job-tuple-icon.ni-job-tuple-icon-srp-date.exp\")\n",
    "            walk_in = experience_walk_in_date_element.text\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            walk_in = \"\"\n",
    "                      \n",
    "                        \n",
    "        job_info['Walk In Date'] = walk_in\n",
    "        job_info['Experience'] = experience\n",
    "\n",
    "        \n",
    "        try:\n",
    "            job_info['Salary'] = job.find_element(By.CLASS_NAME, \"sal-wrap\").text\n",
    "        except:\n",
    "            job_info['Salary'] = \"Not disclosed\"\n",
    "\n",
    "        # Extract location\n",
    "        parent_element = job.find_element(\"css selector\", \"span.ni-job-tuple-icon.ni-job-tuple-icon-srp-location.loc\")\n",
    "        job_info['Location'] = parent_element.find_element(\"xpath\", \"./span\").text\n",
    "\n",
    "        # Extract description\n",
    "        job_info['Description'] = job.find_element(By.CLASS_NAME, \"job-desc\").text\n",
    "\n",
    "        # Extract tags (skills)\n",
    "        job_info['Tags'] = [tag.text for tag in job.find_elements(By.CLASS_NAME, \"tag-li\")]\n",
    "\n",
    "        # Extract posting information (e.g., how many days ago it was posted)\n",
    "        job_info['Posting Info'] = job.find_element(By.CLASS_NAME, \"job-post-day\").text\n",
    "\n",
    "        job_info['Datetime Extracted'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Add the job_info dictionary to job_list\n",
    "        job_list.append(job_info)\n",
    "\n",
    "    return job_list  # Return the list containing all job dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list = []\n",
    "job_list += extract_info(browser)\n",
    "\n",
    "i = 1\n",
    "while url != '':\n",
    "\n",
    "    pagination_div = browser.find_element(By.CLASS_NAME, 'styles_pagination__oIvXh')\n",
    "    \n",
    "    # Find all anchor tags within that div\n",
    "    anchor_tags = pagination_div.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "    next_page = anchor_tags[-1]\n",
    "    print(f'Link: {next_page.get_attribute(\"href\")}, Text: {next_page.text}') \n",
    "\n",
    "    url = next_page.get_attribute(\"href\")\n",
    "    browser.get(url)\n",
    "\n",
    "    sleep(3)\n",
    "\n",
    "    print(\"Next page\")\n",
    "    \n",
    "    job_list += extract_info(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to jobs.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "csv_filename = 'jobs.csv'\n",
    "if job_list:  \n",
    "    headers = job_list[0].keys()\n",
    "    \n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        \n",
    "        writer = csv.DictWriter(file, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(job_list)\n",
    "\n",
    "    print(f\"Data successfully saved to {csv_filename}\")\n",
    "else:\n",
    "    print(\"No data to write to CSV.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
